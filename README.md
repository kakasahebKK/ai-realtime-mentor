# ai-realtime-mentor

# Run instructions:
# 1. Create a virtual environment: python -m venv venv
# 2. Activate it: source venv/bin/activate (Linux/Mac) or venv\Scripts\activate (Windows)
# 3. Install dependencies: pip install -r requirements.txt
# 4. Start Ollama server (make sure llama2 model is available)
# 5. Start FastAPI server: uvicorn main:app --reload
# 6. Start Streamlit frontend: streamlit run frontend.py